{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def set_random_seed(seed: int = 50):\n",
    "    \"\"\"\n",
    "    Set the random seed for reproducibility.\n",
    "\n",
    "    Args:\n",
    "        seed (int): The seed value to use. Default is 50.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_random_seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function(ratings: torch.Tensor, user_embeddings: torch.Tensor, item_embeddings: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Loss function for matrix factorization.\n",
    "\n",
    "    Args:\n",
    "        ratings (torch.Tensor): Rating data\n",
    "        user_embeddings (torch.Tensor): User embeddings \n",
    "        item_embeddings (torch.Tensor): Item embeddings \n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The loss function value.\n",
    "    \"\"\"\n",
    "    predictions = torch.mm(user_embeddings, item_embeddings.T)\n",
    "\n",
    "    mask = ratings > 0\n",
    "    masked_predictions = mask * predictions\n",
    "\n",
    "    loss = ((ratings - masked_predictions) ** 2).sum()\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradients(ratings: torch.Tensor, user_embeddings: torch.Tensor, item_embeddings: torch.Tensor, mask: torch.Tensor) -> tuple:\n",
    "    \"\"\"\n",
    "    Calculate gradients directly, without backpropagation.\n",
    "\n",
    "    Args:\n",
    "        ratings (torch.Tensor): Rating data.\n",
    "        user_embeddings (torch.Tensor): User embeddings.\n",
    "        item_embeddings (torch.Tensor): Item embeddings.\n",
    "        mask (torch.Tensor): Mask tensor to filter out non-relevant entries.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Gradients of the user and item embeddings.\n",
    "    \"\"\"\n",
    "    predictions = user_embeddings.matmul(item_embeddings.T)\n",
    "    masked_predictions = mask * predictions\n",
    "\n",
    "    grad_user_embeddings = -2 * (ratings - masked_predictions).matmul(item_embeddings)\n",
    "    grad_item_embeddings = -2 * (ratings - masked_predictions).T.matmul(user_embeddings)\n",
    "\n",
    "    return grad_user_embeddings, grad_item_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path: Path) -> tuple:\n",
    "    \"\"\"\n",
    "    Load the dataset.\n",
    "\n",
    "    Args:\n",
    "        data_path (Path): The path to the data directory.\n",
    "\n",
    "    Returns:\n",
    "        tuple:\n",
    "            real_ratings (ndarray): Real ratings of users (unseen by attackers).\n",
    "            user_gradients (ndarray): User gradients (unseen by attackers).\n",
    "            item_gradients (ndarray): Item gradients (visible to attackers).\n",
    "            user_embeddings (ndarray): User embeddings (unseen by attackers).\n",
    "            item_embeddings (ndarray): Item embeddings (visible to attackers).\n",
    "            training_loss (ndarray): Loss during user training (not currently used).\n",
    "    \"\"\"\n",
    "    real_ratings = np.load(data_path.joinpath('R.npy'))\n",
    "    user_gradients = np.load(data_path.joinpath('X_grad.npy'))\n",
    "    item_gradients = np.load(data_path.joinpath('y_grad.npy'))\n",
    "    user_embeddings = np.load(data_path.joinpath('X_embedding.npy'))\n",
    "    item_embeddings = np.load(data_path.joinpath('y_embedding.npy'))\n",
    "    training_loss = np.load(data_path.joinpath('loss_g.npy'))\n",
    "    \n",
    "    return real_ratings, user_gradients, item_gradients, user_embeddings, item_embeddings, training_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_function_dummy_gradient(predicted_gradient: torch.Tensor, true_gradient: torch.Tensor) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distance between the dummy gradient and the user-uploaded gradient.\n",
    "\n",
    "    Args:\n",
    "        predicted_gradient (torch.Tensor): Dummy gradient.\n",
    "        true_gradient (torch.Tensor): User-uploaded gradient.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: The Euclidean distance between the two gradients.\n",
    "    \"\"\"\n",
    "    difference = predicted_gradient - true_gradient\n",
    "    distance = torch.sum(difference ** 2)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing user 0\n",
      "Processing user 1\n",
      "Processing user 2\n",
      "Processing user 3\n",
      "Processing user 4\n",
      "Processing user 5\n",
      "Processing user 6\n",
      "Processing user 7\n",
      "Processing user 8\n",
      "Processing user 9\n",
      "Processing user 10\n",
      "Processing user 11\n",
      "Processing user 12\n",
      "Processing user 13\n",
      "Processing user 14\n",
      "Processing user 15\n",
      "Processing user 16\n",
      "Processing user 17\n",
      "Processing user 18\n",
      "Processing user 19\n",
      "Processing user 20\n",
      "Processing user 21\n",
      "Processing user 22\n",
      "Processing user 23\n",
      "Processing user 24\n",
      "Processing user 25\n",
      "Processing user 26\n",
      "Processing user 27\n",
      "Processing user 28\n",
      "Processing user 29\n"
     ]
    }
   ],
   "source": [
    "final_loss_list = []\n",
    "final_dummy_ratings = []\n",
    "final_ratings = []\n",
    "\n",
    "for user_id in range(30):\n",
    "    print(f'Processing user {user_id}')\n",
    "    data_path = Path(f'./data/{user_id}/')\n",
    "    ratings, user_gradients, item_gradients, user_embeddings, item_embeddings, training_loss = read_data(data_path)\n",
    "\n",
    "    user_embedding_1 = user_embeddings[0]\n",
    "    user_embedding_2 = user_embeddings[1]\n",
    "\n",
    "    item_embedding_1 = item_embeddings[0]\n",
    "    item_embedding_2 = item_embeddings[1]\n",
    "    item_embedding_3 = item_embeddings[2]\n",
    "\n",
    "    ratings_copy = ratings.copy()\n",
    "\n",
    "    user_gradient_1 = user_gradients[0]\n",
    "    user_gradient_2 = user_gradients[1]\n",
    "\n",
    "    item_gradient_1 = item_gradients[0]\n",
    "    item_gradient_2 = item_gradients[1]\n",
    "\n",
    "    user_embedding_1 = torch.tensor(user_embedding_1, dtype=torch.float32)\n",
    "    user_embedding_2 = torch.tensor(user_embedding_2, dtype=torch.float32)\n",
    "\n",
    "    item_embedding_1 = torch.tensor(item_embedding_1, dtype=torch.float32)\n",
    "    item_embedding_2 = torch.tensor(item_embedding_2, dtype=torch.float32)\n",
    "    item_embedding_3 = torch.tensor(item_embedding_3, dtype=torch.float32)\n",
    "\n",
    "    ratings_copy = torch.tensor(ratings_copy, dtype=torch.float32)\n",
    "\n",
    "    user_gradient_1 = torch.tensor(user_gradient_1, dtype=torch.float32)\n",
    "    user_gradient_2 = torch.tensor(user_gradient_2, dtype=torch.float32)\n",
    "\n",
    "    item_gradient_1 = torch.tensor(item_gradient_1, dtype=torch.float32)\n",
    "    item_gradient_2 = torch.tensor(item_gradient_2, dtype=torch.float32)\n",
    "\n",
    "    torch.random.manual_seed(42)\n",
    "    dummy_user_embedding = torch.rand_like(user_embedding_1, requires_grad=True)\n",
    "    dummy_ratings = torch.randint_like(ratings_copy, low=0, high=6, requires_grad=True)\n",
    "\n",
    "    mask = ratings_copy > 1e-6\n",
    "\n",
    "    optimizer = torch.optim.LBFGS([dummy_user_embedding, dummy_ratings])\n",
    "    loss_list = []\n",
    "\n",
    "    for step in range(1, 500):\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "            pred1, pred2 = calculate_gradients(dummy_ratings, dummy_user_embedding, item_embedding_1, mask)\n",
    "\n",
    "            loss1 = loss_function_dummy_gradient(pred2, item_gradient_1)\n",
    "            temp_dummy_user_embedding = dummy_user_embedding - 0.0005 * pred1\n",
    "\n",
    "            pred1, pred2 = calculate_gradients(dummy_ratings, temp_dummy_user_embedding, item_embedding_2, mask)\n",
    "            loss2 = loss_function_dummy_gradient(pred2, item_gradient_2)\n",
    "            total_loss = loss1 + loss2\n",
    "            total_loss.backward()\n",
    "            loss_list.append(total_loss.item())\n",
    "            return total_loss\n",
    "\n",
    "        optimizer.step(closure)\n",
    "\n",
    "    final_loss_list.append(loss_list)\n",
    "    final_dummy_ratings.append(dummy_ratings.abs().detach().numpy())\n",
    "    final_ratings.append(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual ratings for the first user: [5. 4. 3. 5. 4. 1. 5. 3. 2. 5. 5. 5. 5. 5. 4. 5. 4. 1. 4. 2. 1. 3. 5. 4.\n",
      " 2. 3. 2. 5. 4. 5. 4. 4. 5. 3. 5. 4. 4. 3. 3. 5. 4. 5. 4. 5. 5. 4. 3. 2.\n",
      " 5. 4. 4. 3. 4. 3. 3. 3. 4. 3. 4. 4. 4. 1. 4. 5. 5. 4. 3. 5. 4. 5. 4. 5.\n",
      " 3. 5. 2. 4. 5. 3. 4. 3. 5. 2. 2. 1. 2. 4. 5. 5. 5. 1. 5. 5. 3. 3. 5. 1.\n",
      " 4. 4. 5. 3. 2. 5. 4. 5. 3. 1. 4. 4. 3. 5. 1. 3. 1. 2. 1. 2. 3. 2. 5. 4.\n",
      " 5. 5. 2. 4. 3. 3. 4. 4. 4. 3. 5. 5. 2. 5. 5. 5. 5. 5. 5. 5. 5. 3. 3. 5.\n",
      " 4. 5. 4. 4. 4. 4. 3. 3. 5. 4. 4. 4. 5. 4. 3. 3. 5. 4. 5. 3. 4. 5. 5. 4.\n",
      " 4. 3. 4. 2. 4. 3. 3. 1. 3. 5. 4. 5. 4. 4. 1. 3. 2. 4. 4. 2. 4. 3. 4. 5.\n",
      " 1. 2. 2. 5. 1. 4. 4. 4. 4. 2. 5. 2. 4. 1. 1. 3. 1. 4. 1. 4. 5. 5. 5. 2.\n",
      " 3.]\n"
     ]
    }
   ],
   "source": [
    "# Print the actual ratings for the first user\n",
    "actual_ratings = final_ratings[0][final_ratings[0] > 0]\n",
    "print(\"Actual ratings:\", actual_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy ratings: [4.999999   3.9999964  2.9999971  5.0000024  3.9999995  0.99999905\n",
      " 4.999999   2.9999974  1.9999977  5.0000014  5.         5.\n",
      " 5.000001   4.9999995  4.000001   5.000002   3.9999983  1.0000018\n",
      " 3.999999   1.9999986  0.9999999  3.0000007  4.9999986  3.999998\n",
      " 1.999998   3.         1.999998   4.9999976  3.9999993  4.9999995\n",
      " 4.0000005  3.9999979  4.9999986  2.9999986  4.9999995  4.0000024\n",
      " 4.0000005  2.9999983  3.0000005  4.999998   3.9999993  4.9999995\n",
      " 3.9999971  4.9999976  4.999999   4.         2.9999957  2.\n",
      " 5.0000005  4.0000014  3.9999986  2.9999986  3.9999998  2.9999983\n",
      " 2.9999986  2.999997   3.999997   2.9999983  4.000001   3.999999\n",
      " 3.9999995  0.9999999  3.9999998  4.9999976  5.         3.999998\n",
      " 2.9999986  5.0000005  4.         4.9999976  4.0000005  4.9999986\n",
      " 2.9999979  5.0000005  1.9999988  3.9999979  5.000001   2.9999988\n",
      " 3.9999995  2.9999971  4.9999995  1.9999986  2.0000002  0.9999978\n",
      " 1.9999987  4.0000014  5.         4.999999   5.         0.9999993\n",
      " 5.         5.000003   2.9999979  2.9999971  5.0000005  0.99999774\n",
      " 3.999997   3.9999998  5.0000024  2.999997   1.9999976  4.999996\n",
      " 4.0000005  4.9999995  3.0000002  0.99999964 3.9999967  3.9999983\n",
      " 2.9999962  4.9999986  0.99999905 3.0000007  0.9999996  1.999997\n",
      " 0.99999917 2.0000005  2.9999993  1.9999983  4.999998   3.9999998\n",
      " 5.0000005  4.9999986  1.9999989  3.999999   3.0000007  2.9999995\n",
      " 3.9999986  4.000001   3.9999998  3.0000005  4.9999976  5.\n",
      " 1.9999987  5.         4.9999995  4.999997   5.0000014  4.9999986\n",
      " 4.999997   4.999999   5.         2.9999988  2.9999988  4.9999967\n",
      " 3.9999971  4.9999995  4.000002   3.999998   3.999998   3.9999995\n",
      " 2.9999988  3.         5.0000024  4.000003   3.999998   3.9999993\n",
      " 5.         3.9999988  2.999999   2.9999998  5.         3.999998\n",
      " 5.0000005  3.0000005  4.0000014  4.9999986  4.9999976  4.0000014\n",
      " 4.0000005  3.0000012  4.0000005  2.         3.9999971  3.\n",
      " 2.9999998  0.9999999  2.9999988  5.000001   3.9999988  4.999997\n",
      " 4.         3.9999983  1.0000006  2.9999955  2.         3.9999971\n",
      " 3.9999998  1.999998   3.9999983  3.0000012  3.9999986  4.999999\n",
      " 1.0000002  1.9999981  1.9999975  5.000002   1.0000011  4.0000005\n",
      " 3.9999957  3.9999995  3.999998   1.9999976  5.0000024  1.999996\n",
      " 3.999999   0.99999803 0.9999992  3.0000005  0.9999991  3.9999986\n",
      " 0.999999   4.         5.0000024  4.9999995  4.999996   1.9999971\n",
      " 2.9999993 ]\n"
     ]
    }
   ],
   "source": [
    "# Print the dummy ratings\n",
    "actual_dummy_ratings = final_dummy_ratings[0][final_ratings[0] > 0]\n",
    "print(\"Dummy ratings:\", actual_dummy_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results\n",
    "np.save('final_dummyR.npy', np.array(final_dummy_ratings))\n",
    "np.save('final_R.npy', np.array(final_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
